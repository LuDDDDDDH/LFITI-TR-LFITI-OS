{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab94a07b-0b3a-4622-bd98-12ca85fce093",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ Radiomcis feature selection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def plot_elastic_net_path_vertical_no_block(X, y, feature_names, l1_ratio=0.5, n_alphas=100, cv=5):\n",
    "    \"\"\"\n",
    "    Main plot and legend are arranged vertically.\n",
    "    The legend is manually formatted as text and does not block the axes.\n",
    "    \"\"\"\n",
    "    eps = 1e-3\n",
    "    alphas = np.logspace(np.log10(eps), np.log10(1), n_alphas)\n",
    "    enet_cv = ElasticNetCV(\n",
    "        l1_ratio=l1_ratio,\n",
    "        alphas=alphas,\n",
    "        cv=cv,\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "    enet_cv.fit(X, y)\n",
    "\n",
    "    coef_path = []\n",
    "    enet = ElasticNet(l1_ratio=l1_ratio, max_iter=1000)\n",
    "    for alpha in alphas:\n",
    "        enet.set_params(alpha=alpha)\n",
    "        enet.fit(X, y)\n",
    "        coef_path.append(enet.coef_)\n",
    "    coef_path = np.array(coef_path)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = fig.add_gridspec(2, 1, height_ratios=[1.1, 0.9], hspace=0.10)\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    # All paths in gray\n",
    "    ax.plot(np.log10(alphas), coef_path, color='gray', linewidth=0.5, alpha=0.1)\n",
    "\n",
    "    final_coef = enet_cv.coef_\n",
    "    nonzero_idx = abs(final_coef) > 1e-5\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, sum(nonzero_idx)))\n",
    "\n",
    "    # Highlighted features\n",
    "    feature_lines = []\n",
    "    coef_idx = 0\n",
    "    for idx, (is_selected, coef) in enumerate(zip(nonzero_idx, final_coef)):\n",
    "        if is_selected:\n",
    "            line = ax.plot(np.log10(alphas), coef_path[:, idx],\n",
    "                           linewidth=2, color=colors[coef_idx],\n",
    "                           label=f'{feature_names[idx]} ({coef:.4f})')[0]\n",
    "            feature_lines.append((line, f'{feature_names[idx]} ({coef:.4f})'))\n",
    "            coef_idx += 1\n",
    "\n",
    "    # Optimal alpha line\n",
    "    optimal_line = ax.axvline(np.log10(enet_cv.alpha_), color='r', linestyle='--', alpha=0.8)\n",
    "    feature_lines.append((optimal_line, f'Optimal α = {enet_cv.alpha_:.2e}'))\n",
    "\n",
    "    ax.set_xlabel('log(α)', fontsize=16)\n",
    "    ax.set_ylabel('Coefficients', fontsize=24)\n",
    "    ax.grid(True, alpha=0.1)\n",
    "    ax.set_title('Elastic Net Path', fontsize=24, pad=20)\n",
    "\n",
    "    # Lower subplot for legend, center-aligned text only\n",
    "    ax_leg = fig.add_subplot(gs[1, 0])\n",
    "    ax_leg.axis('off')\n",
    "\n",
    "    # Legend text content\n",
    "    legend_texts = [f\"{line[1]}\" for line in feature_lines]\n",
    "    model_info = [\n",
    "        f\"Total features: {X.shape[1]}\",\n",
    "        f\"Selected features: {sum(nonzero_idx)}\",\n",
    "        f\"Optimal α: {enet_cv.alpha_:.2e}\",\n",
    "        f\"l1_ratio: {l1_ratio:.2f}\",\n",
    "        f\"Mean CV score: {enet_cv.score(X, y):.4f}\"\n",
    "    ]\n",
    "    # Colored small squares\n",
    "    y_start = 1.0\n",
    "    line_height = 0.09\n",
    "    for i, (line, label) in enumerate(feature_lines):\n",
    "        color = line.get_color()\n",
    "        # Colored rectangle\n",
    "        ax_leg.plot([0.02, 0.07], [y_start - i*line_height]*2, color=color, linewidth=6, solid_capstyle='round')\n",
    "        ax_leg.text(0.10, y_start - i*line_height, label, va='center', fontsize=20)\n",
    "\n",
    "    # Optimal alpha dashed line\n",
    "    ax_leg.plot([0.02, 0.07], [y_start - (len(feature_lines)-1)*line_height]*2, color='red', linestyle='--', linewidth=3)\n",
    "    ax_leg.text(0.10, y_start - (len(feature_lines)-1)*line_height, feature_lines[-1][1], va='center', fontsize=20, color='red')\n",
    "\n",
    "    # Model info\n",
    "    for j, info in enumerate(model_info):\n",
    "        ax_leg.text(0.02, y_start - (len(feature_lines)+0.5+j)*line_height, info, va='center', fontsize=20)\n",
    "\n",
    "    ax_leg.set_xlim(0, 1)\n",
    "    ax_leg.set_ylim(0, 1.05)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return enet_cv, final_coef\n",
    "\n",
    "def visualize_elastic_net_selected(model, feature_names, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize only features selected by Elastic Net (nonzero coefficients) and their coefficients\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['font.family'] = 'Arial'\n",
    "    mpl.rcParams['font.size'] = 16\n",
    "    plt.figure(figsize=(10, max(4, 0.6*sum(abs(model.coef_) > 1e-5))))\n",
    "    \n",
    "    coefficients = model.coef_.flatten()\n",
    "    # Select only nonzero coefficient features\n",
    "    selected = np.abs(coefficients) > 1e-5\n",
    "    selected_coefs = coefficients[selected]\n",
    "    selected_features = np.array(feature_names)[selected]\n",
    "    \n",
    "    # Sort by absolute value\n",
    "    sorted_indices = np.argsort(np.abs(selected_coefs))[::-1]\n",
    "    selected_coefs = selected_coefs[sorted_indices]\n",
    "    selected_features = selected_features[sorted_indices]\n",
    "    colors = ['#3498db' if coef > 0 else '#e74c3c' for coef in selected_coefs]\n",
    "    \n",
    "    plt.barh(range(len(selected_coefs)), selected_coefs, color=colors)\n",
    "    plt.yticks(range(len(selected_coefs)), selected_features, fontsize=18)\n",
    "    plt.xlabel('Coefficient Value', fontsize=16)\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    import sys\n",
    "    data_path = input(\"Please enter the file path: \").strip()\n",
    "    if not data_path:\n",
    "        print(\"No file path provided. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    data = pd.read_excel(data_path)\n",
    "    print(f\"Processing file: {data_path}\\n\")\n",
    "\n",
    "    X = data.iloc[:, 1:].values\n",
    "    y = data.iloc[:, 0].values\n",
    "    original_feature_names = data.columns[1:].tolist()\n",
    "    print(f\"Original number of features: {len(original_feature_names)}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "\n",
    "    var_thresh = VarianceThreshold(threshold=0.01)\n",
    "    X_train_s = var_thresh.fit_transform(X_train_s)\n",
    "    X_test_s = var_thresh.transform(X_test_s)\n",
    "    selected_features_var = var_thresh.get_support()\n",
    "    var_selected_features = [f for i, f in enumerate(original_feature_names)\n",
    "                             if selected_features_var[i]]\n",
    "\n",
    "    print(f\"\\nAfter Variance Threshold Selection:\")\n",
    "    print(f\"Number of features: {len(var_selected_features)}\")\n",
    "\n",
    "    print(\"\\nPlotting Elastic Net path...\")\n",
    "    enet_fitted, final_coefficients = plot_elastic_net_path_vertical_no_block(\n",
    "        X_train_s,\n",
    "        y_train,\n",
    "        var_selected_features,\n",
    "        l1_ratio=0.5,\n",
    "        n_alphas=100,\n",
    "        cv=5\n",
    "    )\n",
    "    plt.savefig('elastic_net_path_vertical_no_block.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nBest parameters:\")\n",
    "    print(f\"Optimal alpha: {enet_fitted.alpha_:.2e}\")\n",
    "    print(f\"l1_ratio: {enet_fitted.l1_ratio_:.2f}\")\n",
    "    print(f\"Number of selected features: {sum(abs(final_coefficients) > 1e-5)}\")\n",
    "\n",
    "    print(\"\\nSelected features and their coefficients:\")\n",
    "    selected_features = pd.DataFrame({\n",
    "        'Feature': var_selected_features,\n",
    "        'Coefficient': final_coefficients\n",
    "    })\n",
    "    selected_features = selected_features[abs(selected_features['Coefficient']) > 1e-5]\n",
    "    selected_features = selected_features.sort_values('Coefficient',\n",
    "                                                      key=abs,\n",
    "                                                      ascending=False)\n",
    "    print(selected_features)\n",
    "    selected_features.to_excel('elastic_net_features.xlsx', index=False)\n",
    "    # Visualize selected features' coefficients\n",
    "    print(\"\\nPlotting selected features coefficient bar chart...\")\n",
    "    visualize_elastic_net_selected(enet_fitted, var_selected_features, save_path='elastic_net_selected_coefficients.pdf')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3e70fe-829a-49a4-be6b-918ad098b26c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multi-model screening --------------------------- Clinical modal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "# Hide warnings in output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "data_path = input(\"Please enter the file path: \").strip()\n",
    "data = pd.read_excel(data_path)\n",
    "data.describe()\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.iloc[:, 1:].values  # Convert to NumPy array\n",
    "y = data.iloc[:, 0].values   # Convert to NumPy array\n",
    "\n",
    "# Get feature names\n",
    "feature_names = data.columns[1:]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Data standardization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------\n",
    "# Univariate logistic regression for initial feature selection\n",
    "# ---------------------------\n",
    "p_values = []\n",
    "selected_features = []\n",
    "\n",
    "for i in range(X_train_s.shape[1]):\n",
    "    X_single = X_train_s[:, i].reshape(-1, 1)\n",
    "    logit_model = sm.Logit(y_train, sm.add_constant(X_single))\n",
    "    result = logit_model.fit(disp=0)\n",
    "    p_value = result.pvalues[1]\n",
    "    p_values.append(p_value)\n",
    "    if p_value < 0.05:  # Significance level set at 0.05\n",
    "        selected_features.append(i)\n",
    "\n",
    "# Indices of selected features (from univariate logistic regression)\n",
    "selected_features = np.array(selected_features)\n",
    "\n",
    "# Show names of initially selected features\n",
    "print(\"Initially selected feature names (Univariate Logistic Regression):\")\n",
    "print(feature_names[selected_features])\n",
    "\n",
    "# ---------------------------\n",
    "# Further feature selection using Elastic Net\n",
    "# ---------------------------\n",
    "if len(selected_features) > 0:\n",
    "    X_train_selected = X_train_s[:, selected_features]\n",
    "    X_test_selected = X_test_s[:, selected_features]\n",
    "    \n",
    "    # Elastic Net Logistic Regression\n",
    "    # l1_ratio controls the mix of L1 and L2 regularization, C is the inverse of regularization strength, use saga solver\n",
    "    elastic_net_model = LogisticRegression(random_state=42, penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0, max_iter=5000)\n",
    "    elastic_net_model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Get model coefficients (shape: (1, n_features))\n",
    "    coef = elastic_net_model.coef_.flatten()\n",
    "    \n",
    "    # Set a threshold: coefficients with absolute value > threshold are considered important features\n",
    "    threshold = 1e-4\n",
    "    elastic_net_selected_indices = np.where(np.abs(coef) > threshold)[0]\n",
    "    \n",
    "    # If no features remain after elastic net, retain univariate selection\n",
    "    if len(elastic_net_selected_indices) == 0:\n",
    "        multistep_selected_features = selected_features\n",
    "    else:\n",
    "        multistep_selected_features = selected_features[elastic_net_selected_indices]\n",
    "    \n",
    "    # Show finally selected feature names\n",
    "    print(\"Final selected feature names (Elastic Net Regression):\")\n",
    "    print(feature_names[multistep_selected_features])\n",
    "else:\n",
    "    print(\"No features passed univariate logistic regression selection.\")\n",
    "    multistep_selected_features = np.array([])\n",
    "\n",
    "# If no features remain after screening, exit\n",
    "if multistep_selected_features.size == 0:\n",
    "    raise ValueError(\"No valid features passed selection.\")\n",
    "\n",
    "# Update training and testing sets\n",
    "X_train_final = X_train_s[:, multistep_selected_features]\n",
    "X_test_final = X_test_s[:, multistep_selected_features]\n",
    "\n",
    "# ---------------------------\n",
    "# Define models\n",
    "# ---------------------------\n",
    "base_models = [\n",
    "    ('lr', LogisticRegression(random_state=42, penalty='l2', C=0.1)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42, max_depth=5)),\n",
    "    ('svm', SVC(probability=True, random_state=42, C=0.1))\n",
    "]\n",
    "\n",
    "# Bagging model\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42, max_depth=5), n_estimators=50, random_state=42)\n",
    "\n",
    "# Boosting model, AdaBoost with Random Forest as base estimator\n",
    "boosting_model = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=10, random_state=42, max_depth=5), n_estimators=50, random_state=42)\n",
    "\n",
    "# Stacking model\n",
    "stacking_model = StackingClassifier(classifiers=[clf for _, clf in base_models], meta_classifier=LogisticRegression(random_state=42, penalty='l2', C=0.1))\n",
    "\n",
    "# Rotation Forest model (random forest as replacement)\n",
    "rotation_forest_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)\n",
    "\n",
    "# Gradient Boosting model with randomness\n",
    "gtb_randomness_model = GradientBoostingClassifier(n_estimators=50, random_state=42, subsample=0.8, max_depth=5)\n",
    "\n",
    "# Model dictionary\n",
    "models = {\n",
    "    \"Bagging\": bagging_model,\n",
    "    \"Boosting\": boosting_model,\n",
    "    \"Stacking\": stacking_model,\n",
    "    \"Rotation Forest\": rotation_forest_model,\n",
    "    \"GTB Randomness\": gtb_randomness_model,\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# 5-fold cross-validation AUC on training set\n",
    "# ---------------------------\n",
    "kf_train = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = {}\n",
    "print(\"Training set cross-validation AUC:\")\n",
    "for name, model in models.items():\n",
    "    aucs_train = cross_val_score(model, X_train_final, y_train, cv=kf_train, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_results[name] = aucs_train\n",
    "    print(f\"{name} - Mean AUC: {aucs_train.mean():.2f} +/- {aucs_train.std():.2f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5-fold cross-validation AUC on testing set\n",
    "# ---------------------------\n",
    "kf_test = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"\\nTesting set cross-validation AUC:\")\n",
    "for name, model in models.items():\n",
    "    aucs_test = cross_val_score(model, X_test_final, y_test, cv=kf_test, scoring='roc_auc', n_jobs=-1)\n",
    "    print(f\"{name} - Mean AUC: {aucs_test.mean():.2f} +/- {aucs_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2fc5a51-b607-4a0e-8177-b609aaa4b705",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multi-model screening --------------------------- Radiomics modal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "import warnings\n",
    "\n",
    "# Hide warnings in output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "data_path = input(\"Please enter the file path: \").strip()\n",
    "data = pd.read_excel(data_path)\n",
    "data.describe()\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.iloc[:, 1:].values  # Convert to NumPy array\n",
    "y = data.iloc[:, 0].values   # Convert to NumPy array\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Data standardization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# Initial feature selection (Variance Threshold)\n",
    "var_thresh = VarianceThreshold(threshold=0.01)\n",
    "X_train_s = var_thresh.fit_transform(X_train_s)\n",
    "X_test_s = var_thresh.transform(X_test_s)\n",
    "\n",
    "# Further feature selection with Elastic Net\n",
    "elastic_net = ElasticNetCV(cv=5, random_state=42)\n",
    "select_from_model = SelectFromModel(estimator=elastic_net)\n",
    "X_train_s = select_from_model.fit_transform(X_train_s, y_train)\n",
    "X_test_s = select_from_model.transform(X_test_s)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('lr', LogisticRegression(random_state=42, penalty='l2', C=0.1)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42, max_depth=5)),\n",
    "    ('svm', SVC(probability=True, random_state=42, C=0.1))\n",
    "]\n",
    "\n",
    "# Bagging model\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42, max_depth=5), n_estimators=50, random_state=42)\n",
    "\n",
    "# Boosting model with Random Forest as base estimator\n",
    "boosting_model = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=10, random_state=42, max_depth=5), n_estimators=50, random_state=42)\n",
    "\n",
    "# Stacking model\n",
    "stacking_model = StackingClassifier(classifiers=[clf for _, clf in base_models], meta_classifier=LogisticRegression(random_state=42, penalty='l2', C=0.1))\n",
    "\n",
    "# # Voting model (uncomment if needed)\n",
    "# voting_model = VotingClassifier(estimators=base_models, voting='soft')\n",
    "\n",
    "# Rotation Forest model\n",
    "rotation_forest_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)\n",
    "\n",
    "# Gradient Boosting model with randomness\n",
    "gtb_randomness_model = GradientBoostingClassifier(n_estimators=50, random_state=42, subsample=0.8, max_depth=5)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Bagging\": bagging_model,\n",
    "    \"Boosting\": boosting_model,\n",
    "    \"Stacking\": stacking_model,\n",
    "    \"Rotation Forest\": rotation_forest_model,\n",
    "    \"GTB Randomness\": gtb_randomness_model,\n",
    "}\n",
    "\n",
    "# 5-fold cross-validation and AUC computation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    aucs = cross_val_score(model, X_test_s, y_test, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_results[name] = aucs\n",
    "    print(f\"{name} - Mean AUC: {aucs.mean():.4f} +/- {aucs.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd11f01-4af3-44f4-b02c-cc25ee507973",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning---------------------------- Clinical modal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "# Hide warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "data_path = input(\"Please enter the file path: \").strip()\n",
    "data = pd.read_excel(data_path)\n",
    "data.describe()\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "# Get feature names\n",
    "feature_names = data.columns[1:]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------\n",
    "# Univariate logistic regression for initial feature selection\n",
    "# ---------------------------\n",
    "p_values = []\n",
    "selected_features = []\n",
    "\n",
    "for i in range(X_train_s.shape[1]):\n",
    "    X_single = X_train_s[:, i].reshape(-1, 1)\n",
    "    logit_model = sm.Logit(y_train, sm.add_constant(X_single))\n",
    "    result = logit_model.fit(disp=0)\n",
    "    p_value = result.pvalues[1]\n",
    "    p_values.append(p_value)\n",
    "    if p_value < 0.05:  # Significance level\n",
    "        selected_features.append(i)\n",
    "\n",
    "# Indices of selected features (univariate logistic regression)\n",
    "selected_features = np.array(selected_features)\n",
    "\n",
    "# Display names of initially selected features\n",
    "print(\"Initially selected feature names (Univariate Logistic Regression):\")\n",
    "print(feature_names[selected_features])\n",
    "\n",
    "# ---------------------------\n",
    "# Further feature selection using Elastic Net\n",
    "# ---------------------------\n",
    "if len(selected_features) > 0:\n",
    "    X_train_selected = X_train_s[:, selected_features]\n",
    "    X_test_selected = X_test_s[:, selected_features]\n",
    "    \n",
    "    # Elastic Net Logistic Regression\n",
    "    elastic_net_model = LogisticRegression(random_state=42, penalty='elasticnet', \n",
    "                                         solver='saga', l1_ratio=0.5, C=1.0, max_iter=5000)\n",
    "    elastic_net_model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Get model coefficients\n",
    "    coef = elastic_net_model.coef_.flatten()\n",
    "    \n",
    "    # Set a threshold: coefficients with abs > threshold are important features\n",
    "    threshold = 1e-4\n",
    "    elastic_net_selected_indices = np.where(np.abs(coef) > threshold)[0]\n",
    "    \n",
    "    # If no features remain after elastic net, retain univariate selection\n",
    "    if len(elastic_net_selected_indices) == 0:\n",
    "        multistep_selected_features = selected_features\n",
    "    else:\n",
    "        multistep_selected_features = selected_features[elastic_net_selected_indices]\n",
    "    \n",
    "    # Display final selected features\n",
    "    print(\"\\nFinal selected feature names (Elastic Net Regression):\")\n",
    "    print(feature_names[multistep_selected_features])\n",
    "else:\n",
    "    print(\"No features passed univariate logistic regression selection.\")\n",
    "    multistep_selected_features = np.array([])\n",
    "\n",
    "# Update train/test sets\n",
    "X_train_final = X_train_s[:, multistep_selected_features]\n",
    "X_test_final = X_test_s[:, multistep_selected_features]\n",
    "\n",
    "# ---------------------------\n",
    "# Grid Search for Parameters\n",
    "# ---------------------------\n",
    "def evaluate_model(params, X, y, kf):\n",
    "    \"\"\"Evaluate model performance under given parameters\"\"\"\n",
    "    model = RandomForestClassifier(random_state=42, **params)\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [30, 50, 70],           # Number of trees\n",
    "    'max_depth': [3, 5, 7],                 # Max tree depth\n",
    "    'min_samples_split': [2, 5, 10],        # Min samples to split node\n",
    "}\n",
    "\n",
    "# Store performance for each parameter set\n",
    "results = []\n",
    "\n",
    "# Define cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search\n",
    "print(\"\\nStart parameter optimization...\")\n",
    "for n_estimators in param_grid['n_estimators']:\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for min_samples_split in param_grid['min_samples_split']:\n",
    "            params = {\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split\n",
    "            }\n",
    "            \n",
    "            # 5-fold cross-validation on test set\n",
    "            mean_auc = evaluate_model(params, X_test_final, y_test, kf)\n",
    "            \n",
    "            results.append({\n",
    "                'params': params,\n",
    "                'mean_auc': mean_auc\n",
    "            })\n",
    "            \n",
    "            print(f\"Parameters: {params}\")\n",
    "            print(f\"Mean AUC: {mean_auc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "# Find best parameters\n",
    "best_result = max(results, key=lambda x: x['mean_auc'])\n",
    "print(\"\\nBest parameter combination:\")\n",
    "print(f\"Parameters: {best_result['params']}\")\n",
    "print(f\"AUC: {best_result['mean_auc']:.4f}\")\n",
    "\n",
    "# Visualize grid search results\n",
    "plt.figure(figsize=(12, 6))\n",
    "aucs = [r['mean_auc'] for r in results]\n",
    "param_names = [f\"n:{r['params']['n_estimators']},d:{r['params']['max_depth']},s:{r['params']['min_samples_split']}\" \n",
    "               for r in results]\n",
    "\n",
    "plt.bar(range(len(results)), aucs)\n",
    "plt.xticks(range(len(results)), param_names, rotation=45, ha='right')\n",
    "plt.xlabel('Parameter Combinations')\n",
    "plt.ylabel('Mean AUC')\n",
    "plt.title('Parameter Optimization Results')\n",
    "plt.tight_layout()\n",
    "plt.savefig('parameter_optimization.pdf')\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# Use best parameters for Rotation Forest model\n",
    "# ---------------------------\n",
    "rotation_forest = RandomForestClassifier(random_state=42, **best_result['params'])\n",
    "\n",
    "# ---------------------------\n",
    "# 5-fold cross-validation\n",
    "# ---------------------------\n",
    "# On training set\n",
    "cv_scores_train = cross_val_score(rotation_forest, X_train_final, y_train, \n",
    "                                 cv=kf, scoring='roc_auc')\n",
    "print(\"\\nTraining set 5-fold cross-validation AUC:\")\n",
    "print(f\"Mean AUC: {cv_scores_train.mean():.4f} +/- {cv_scores_train.std():.4f}\")\n",
    "\n",
    "# On test set\n",
    "cv_scores_test = cross_val_score(rotation_forest, X_test_final, y_test, \n",
    "                                cv=kf, scoring='roc_auc')\n",
    "print(\"\\nTest set 5-fold cross-validation AUC:\")\n",
    "print(f\"Mean AUC: {cv_scores_test.mean():.4f} +/- {cv_scores_test.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3056192-cae6-445b-b075-3ccc102f1348",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning---------------------------- Radiomics modal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import warnings\n",
    "\n",
    "# Hide warnings in output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "data_path = input(\"Please enter the file path: \").strip()\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# Initial feature selection (Variance Threshold)\n",
    "var_thresh = VarianceThreshold(threshold=0.01)\n",
    "X_train_s = var_thresh.fit_transform(X_train_s)\n",
    "X_test_s = var_thresh.transform(X_test_s)\n",
    "\n",
    "# Further feature selection with Elastic Net\n",
    "elastic_net = ElasticNetCV(cv=5, random_state=42)\n",
    "select_from_model = SelectFromModel(estimator=elastic_net)\n",
    "X_train_s = select_from_model.fit_transform(X_train_s, y_train)\n",
    "X_test_s = select_from_model.transform(X_test_s)\n",
    "\n",
    "# ---------------------------\n",
    "# Grid search for parameter tuning\n",
    "# ---------------------------\n",
    "def evaluate_model(params, X, y, kf):\n",
    "    \"\"\"Evaluate model performance under given parameters\"\"\"\n",
    "    # Set parameters for base RandomForest\n",
    "    base_rf = RandomForestClassifier(\n",
    "        n_estimators=10,  # keep base model small\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create AdaBoost model\n",
    "    model = AdaBoostClassifier(\n",
    "        estimator=base_rf,\n",
    "        n_estimators=params['n_estimators'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [30, 50, 70],           # AdaBoost iterations\n",
    "    'max_depth': [3, 5, 7],                 # RandomForest base model tree depth\n",
    "    'min_samples_split': [2, 5, 10]         # RandomForest base model min samples split\n",
    "}\n",
    "\n",
    "# Store performance for each parameter set\n",
    "results = []\n",
    "\n",
    "# Define cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search\n",
    "print(\"\\nStarting parameter optimization...\")\n",
    "for n_estimators in param_grid['n_estimators']:\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for min_samples_split in param_grid['min_samples_split']:\n",
    "            params = {\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split\n",
    "            }\n",
    "            \n",
    "            # 5-fold cross-validation on the test set\n",
    "            mean_auc = evaluate_model(params, X_test_s, y_test, kf)\n",
    "            \n",
    "            results.append({\n",
    "                'params': params,\n",
    "                'mean_auc': mean_auc\n",
    "            })\n",
    "            \n",
    "            print(f\"Parameters: {params}\")\n",
    "            print(f\"Mean AUC: {mean_auc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "# Find the best parameters\n",
    "best_result = max(results, key=lambda x: x['mean_auc'])\n",
    "print(\"\\nBest parameter combination:\")\n",
    "print(f\"Parameters: {best_result['params']}\")\n",
    "print(f\"AUC: {best_result['mean_auc']:.4f}\")\n",
    "\n",
    "# Visualize grid search results\n",
    "plt.figure(figsize=(12, 6))\n",
    "aucs = [r['mean_auc'] for r in results]\n",
    "param_names = [f\"n:{r['params']['n_estimators']},d:{r['params']['max_depth']},s:{r['params']['min_samples_split']}\" \n",
    "               for r in results]\n",
    "\n",
    "plt.bar(range(len(results)), aucs)\n",
    "plt.xticks(range(len(results)), param_names, rotation=45, ha='right')\n",
    "plt.xlabel('Parameter Combinations')\n",
    "plt.ylabel('Mean AUC')\n",
    "plt.title('Parameter Optimization Results')\n",
    "plt.tight_layout()\n",
    "plt.savefig('boosting_parameter_optimization.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Use best parameters to create the final model\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=best_result['params']['max_depth'],\n",
    "    min_samples_split=best_result['params']['min_samples_split'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_boosting_model = AdaBoostClassifier(\n",
    "    estimator=best_rf,\n",
    "    n_estimators=best_result['params']['n_estimators'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Evaluate the final model\n",
    "final_scores = cross_val_score(final_boosting_model, X_test_s, y_test, cv=kf, scoring='roc_auc')\n",
    "print(f\"\\nFinal model mean AUC: {final_scores.mean():.4f} +/- {final_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac7132-5ebe-4938-a7b5-4cf3fae2cd33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Early fusion------------------------------------- Clinical and radiomics modals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingClassifier  # Ensure that mlxtend is installed: pip install mlxtend\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Data Loading and Preprocessing\n",
    "# =============================================================================\n",
    "# Load clinical data (modality 1)\n",
    "clinical_data = pd.read_excel(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "X1 = clinical_data.iloc[:, 1:].values\n",
    "y1 = clinical_data.iloc[:, 0].values\n",
    "feature_names1 = clinical_data.columns[1:]\n",
    "\n",
    "# Load imaging data (modality 2)\n",
    "imaging_data = pd.read_excel(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "X2 = imaging_data.iloc[:, 1:].values\n",
    "y2 = imaging_data.iloc[:, 0].values\n",
    "\n",
    "# Assume labels are consistent; otherwise, sample alignment is needed. Use clinical labels for analysis.\n",
    "# Split data, ensuring matching sample order for both modalities\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, stratify=y1, random_state=42)\n",
    "X2_train, X2_test, _, _ = train_test_split(X2, y2, test_size=0.3, stratify=y2, random_state=42)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Feature Processing and Selection\n",
    "# =============================================================================\n",
    "# ------------------------------\n",
    "# Clinical feature processing & selection\n",
    "# ------------------------------\n",
    "scaler1 = StandardScaler()\n",
    "X1_train_s = scaler1.fit_transform(X1_train)\n",
    "X1_test_s = scaler1.transform(X1_test)\n",
    "\n",
    "# Univariate logistic regression for feature selection\n",
    "p_values = []\n",
    "selected_features = []\n",
    "for i in range(X1_train_s.shape[1]):\n",
    "    X_single = X1_train_s[:, i].reshape(-1, 1)\n",
    "    logit_model = sm.Logit(y_train, sm.add_constant(X_single))\n",
    "    result = logit_model.fit(disp=0)\n",
    "    p_value = result.pvalues[1]\n",
    "    p_values.append(p_value)\n",
    "    if p_value < 0.05:\n",
    "        selected_features.append(i)\n",
    "selected_features = np.array(selected_features)\n",
    "\n",
    "print(\"\\nInitial selected clinical features (univariate LR):\")\n",
    "print(feature_names1[selected_features])\n",
    "\n",
    "# Elastic Net for further selection\n",
    "if len(selected_features) > 0:\n",
    "    X1_train_selected = X1_train_s[:, selected_features]\n",
    "    X1_test_selected = X1_test_s[:, selected_features]\n",
    "    elastic_net_model = LogisticRegression(random_state=42, penalty='elasticnet', \n",
    "                                           solver='saga', l1_ratio=0.5, C=1.0, max_iter=5000)\n",
    "    elastic_net_model.fit(X1_train_selected, y_train)\n",
    "    coef = elastic_net_model.coef_.flatten()\n",
    "    threshold = 1e-4\n",
    "    elastic_net_selected_indices = np.where(np.abs(coef) > threshold)[0]\n",
    "    if len(elastic_net_selected_indices) == 0:\n",
    "        multistep_selected_features = selected_features\n",
    "    else:\n",
    "        multistep_selected_features = selected_features[elastic_net_selected_indices]\n",
    "    print(\"\\nFinal selected clinical features (ElasticNet):\")\n",
    "    print(feature_names1[multistep_selected_features])\n",
    "    # Update clinical features with final selection\n",
    "    X1_train_s = X1_train_s[:, multistep_selected_features]\n",
    "    X1_test_s = X1_test_s[:, multistep_selected_features]\n",
    "else:\n",
    "    print(\"No clinical features passed univariate logistic regression.\")\n",
    "    multistep_selected_features = np.array([])\n",
    "\n",
    "# ------------------------------\n",
    "# Imaging feature processing & selection\n",
    "# ------------------------------\n",
    "scaler2 = StandardScaler()\n",
    "X2_train_s = scaler2.fit_transform(X2_train)\n",
    "X2_test_s = scaler2.transform(X2_test)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "var_thresh2 = VarianceThreshold(threshold=0.01)\n",
    "X2_train_s = var_thresh2.fit_transform(X2_train_s)\n",
    "X2_test_s = var_thresh2.transform(X2_test_s)\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "elastic_net2 = ElasticNetCV(cv=5, random_state=42)\n",
    "select_model2 = SelectFromModel(estimator=elastic_net2)\n",
    "X2_train_s = select_model2.fit_transform(X2_train_s, y_train)\n",
    "X2_test_s = select_model2.transform(X2_test_s)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Early Feature Fusion\n",
    "# =============================================================================\n",
    "X_train_fusion = np.concatenate((X1_train_s, X2_train_s), axis=1)\n",
    "X_test_fusion = np.concatenate((X1_test_s, X2_test_s), axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Model Construction and 5-Fold Cross-Validation\n",
    "# =============================================================================\n",
    "base_models = [\n",
    "    ('lr', LogisticRegression(random_state=42, penalty='l2', C=0.1)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42, max_depth=5)),\n",
    "    ('svm', SVC(probability=True, random_state=42, C=0.1))\n",
    "]\n",
    "\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42, max_depth=5), \n",
    "                                  n_estimators=50, random_state=42)\n",
    "boosting_model = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=10, random_state=42, max_depth=5), \n",
    "                                    n_estimators=50, random_state=42)\n",
    "stacking_model = StackingClassifier(classifiers=[clf for _, clf in base_models], \n",
    "                                    meta_classifier=LogisticRegression(random_state=42, penalty='l2', C=0.1))\n",
    "rotation_forest_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)\n",
    "gtb_randomness_model = GradientBoostingClassifier(n_estimators=50, random_state=42, subsample=0.8, max_depth=5)\n",
    "\n",
    "models = {\n",
    "    \"Bagging\": bagging_model,\n",
    "    \"Boosting\": boosting_model,\n",
    "    \"Stacking\": stacking_model,\n",
    "    \"Rotation Forest\": rotation_forest_model,\n",
    "    \"GTB Randomness\": gtb_randomness_model\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = {}\n",
    "print(\"\\n5-Fold CV AUC on Early Fusion Features:\")\n",
    "for name, model in models.items():\n",
    "    aucs = cross_val_score(model, X_train_fusion, y_train, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_results[name] = aucs\n",
    "    print(f\"{name} - Mean AUC: {aucs.mean():.4f} ± {aucs.std():.4f}\")\n",
    "\n",
    "best_model_name = max(cv_results, key=lambda x: cv_results[x].mean())\n",
    "print(f\"\\nBest Model: {best_model_name} (Mean AUC: {cv_results[best_model_name].mean():.4f})\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_train_fusion, y_train)\n",
    "test_auc = roc_auc_score(y_test, best_model.predict_proba(X_test_fusion)[:, 1])\n",
    "print(f\"{best_model_name} Test Set AUC: {test_auc:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Plot CV AUC Distribution (Optional)\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, aucs in cv_results.items():\n",
    "    plt.plot(np.arange(1, 6), aucs, marker='o', label=name)\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"5-Fold Cross-Validation AUC for Various Models\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Show mean AUC for train and test sets in 5-fold\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*40 + \" Train/Test Set 5-Fold Cross-Validation Results \" + \"=\"*40)\n",
    "\n",
    "def evaluate_and_plot_roc(models, X_train, y_train, X_test, y_test, kf):\n",
    "    \"\"\"Evaluate models on train/test set and plot ROC curves.\"\"\"\n",
    "    # Train set\n",
    "    print(\"\\nTrain set 5-fold CV results:\")\n",
    "    for name, model in models.items():\n",
    "        train_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "        print(f\"{name} - Mean AUC: {train_scores.mean():.4f} +/- {train_scores.std():.4f}\")\n",
    "    # Test set\n",
    "    print(\"\\nTest set 5-fold CV results:\")\n",
    "    for name, model in models.items():\n",
    "        test_scores = cross_val_score(model, X_test, y_test, cv=kf, scoring='roc_auc')\n",
    "        print(f\"{name} - Mean AUC: {test_scores.mean():.4f} +/- {test_scores.std():.4f}\")\n",
    "\n",
    "    # ROC plot\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_mean_roc(models, X_train, y_train, kf, \"Training Set\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_mean_roc(models, X_test, y_test, kf, \"Test Set\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mean_roc_curves_comparison.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def plot_mean_roc(models, X, y, cv, title):\n",
    "    \"\"\"Plot mean ROC curves.\"\"\"\n",
    "    for name, model in models.items():\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "                y_prob = model.predict_proba(X[val_idx])[:, 1]\n",
    "            else:\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "                y_prob = model.decision_function(X[val_idx])\n",
    "            from sklearn.metrics import roc_curve, auc\n",
    "            fpr, tpr, _ = roc_curve(y[val_idx], y_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(roc_auc)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_auc = np.std(aucs)\n",
    "        plt.plot(mean_fpr, mean_tpr, \n",
    "                label=f'{name} (AUC = {mean_auc:.3f} ± {std_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Mean ROC Curves ({title})')\n",
    "    plt.legend(loc=\"lower right\", prop={'size': 8})\n",
    "\n",
    "evaluate_and_plot_roc(models, X_train_fusion, y_train, X_test_fusion, y_test, kf)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \" Analysis Complete \" + \"=\"*40)\n",
    "\n",
    "# Optional: save results to Excel\n",
    "def save_results_to_excel(models, X_train, y_train, X_test, y_test, kf):\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        train_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "        test_scores = cross_val_score(model, X_test, y_test, cv=kf, scoring='roc_auc')\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Train_AUC_Mean': train_scores.mean(),\n",
    "            'Train_AUC_Std': train_scores.std(),\n",
    "            'Test_AUC_Mean': test_scores.mean(),\n",
    "            'Test_AUC_Std': test_scores.std()\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_excel('model_comparison_results.xlsx', index=False)\n",
    "    print(\"\\nDetailed results saved to 'model_comparison_results.xlsx'\")\n",
    "\n",
    "save_results_to_excel(models, X_train_fusion, y_train, X_test_fusion, y_test, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f603ba-4c68-47a9-8af2-814c5713a58c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Late fusion-------------------------------------- Clinical and radiomics modals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNetCV\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Data loading and preprocessing\n",
    "# =============================================================================\n",
    "# Load clinical data (modality 1)\n",
    "clinical_data_path = input(\"Please enter the clinical data file path: \").strip()\n",
    "clinical_data = pd.read_excel(clinical_data_path)\n",
    "X1 = clinical_data.iloc[:, 1:].values\n",
    "y1 = clinical_data.iloc[:, 0].values\n",
    "feature_names1 = clinical_data.columns[1:]\n",
    "\n",
    "# Load imaging data (modality 2)\n",
    "imaging_data_path = input(\"Please enter the imaging data file path: \").strip()\n",
    "imaging_data = pd.read_excel(imaging_data_path)\n",
    "X2 = imaging_data.iloc[:, 1:].values\n",
    "y2 = imaging_data.iloc[:, 0].values\n",
    "\n",
    "# Split data\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, stratify=y1, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, stratify=y2, random_state=42)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Feature processing and selection\n",
    "# =============================================================================\n",
    "# Clinical data processing\n",
    "scaler1 = StandardScaler()\n",
    "X1_train_s = scaler1.fit_transform(X1_train)\n",
    "X1_test_s = scaler1.transform(X1_test)\n",
    "\n",
    "# Imaging data processing\n",
    "scaler2 = StandardScaler()\n",
    "X2_train_s = scaler2.fit_transform(X2_train)\n",
    "X2_test_s = scaler2.transform(X2_test)\n",
    "\n",
    "# Clinical feature selection - univariate logistic regression\n",
    "p_values = []\n",
    "selected_features = []\n",
    "\n",
    "for i in range(X1_train_s.shape[1]):\n",
    "    X_single = X1_train_s[:, i].reshape(-1, 1)\n",
    "    logit_model = sm.Logit(y1_train, sm.add_constant(X_single))\n",
    "    result = logit_model.fit(disp=0)\n",
    "    p_value = result.pvalues[1]\n",
    "    p_values.append(p_value)\n",
    "    if p_value < 0.05:\n",
    "        selected_features.append(i)\n",
    "\n",
    "selected_features = np.array(selected_features)\n",
    "\n",
    "print(\"\\nInitially selected features (Univariate Logistic Regression):\")\n",
    "print(feature_names1[selected_features])\n",
    "\n",
    "# Elastic Net for further selection\n",
    "if len(selected_features) > 0:\n",
    "    X1_train_selected = X1_train_s[:, selected_features]\n",
    "    X1_test_selected = X1_test_s[:, selected_features]\n",
    "    elastic_net_model = LogisticRegression(random_state=42, penalty='elasticnet', \n",
    "                                         solver='saga', l1_ratio=0.5, C=1.0, max_iter=5000)\n",
    "    elastic_net_model.fit(X1_train_selected, y1_train)\n",
    "    coef = elastic_net_model.coef_.flatten()\n",
    "    threshold = 1e-4\n",
    "    elastic_net_selected_indices = np.where(np.abs(coef) > threshold)[0]\n",
    "    if len(elastic_net_selected_indices) == 0:\n",
    "        multistep_selected_features = selected_features\n",
    "    else:\n",
    "        multistep_selected_features = selected_features[elastic_net_selected_indices]\n",
    "    print(\"\\nFinal selected features (Elastic Net Regression):\")\n",
    "    print(feature_names1[multistep_selected_features])\n",
    "    X1_train_s = X1_train_s[:, multistep_selected_features]\n",
    "    X1_test_s = X1_test_s[:, multistep_selected_features]\n",
    "else:\n",
    "    print(\"No features passed univariate logistic regression selection.\")\n",
    "    multistep_selected_features = np.array([])\n",
    "\n",
    "# Imaging feature selection\n",
    "var_thresh2 = VarianceThreshold(threshold=0.01)\n",
    "X2_train_s = var_thresh2.fit_transform(X2_train_s)\n",
    "X2_test_s = var_thresh2.transform(X2_test_s)\n",
    "\n",
    "elastic_net2 = ElasticNetCV(cv=5, random_state=42)\n",
    "select_model2 = SelectFromModel(estimator=elastic_net2)\n",
    "X2_train_s = select_model2.fit_transform(X2_train_s, y2_train)\n",
    "X2_test_s = select_model2.transform(X2_test_s)\n",
    "\n",
    "# Get features after variance threshold\n",
    "var_selected_features = np.where(var_thresh2.get_support())[0]\n",
    "features_after_var = imaging_data.columns[1:][var_selected_features]\n",
    "\n",
    "# Get Elastic Net selected features\n",
    "elastic_net_selected_features = np.where(select_model2.get_support())[0]\n",
    "final_imaging_features = features_after_var[elastic_net_selected_features]\n",
    "\n",
    "print(\"\\nImaging modality feature selection results:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Original feature count: {len(imaging_data.columns[1:])}\")\n",
    "print(f\"After variance threshold: {len(features_after_var)}\")\n",
    "print(f\"After Elastic Net: {len(final_imaging_features)}\")\n",
    "print(\"\\nFinal selected imaging features:\")\n",
    "for i, feature in enumerate(final_imaging_features, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "selected_features_mod2 = final_imaging_features\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Define late fusion classifier\n",
    "# =============================================================================\n",
    "class LateFusionClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_models, meta_model):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        \n",
    "    def fit(self, X1, X2, y):\n",
    "        self.base_models_ = [clone(model) for model in self.base_models]\n",
    "        self.base_models_[0].fit(X1, y)\n",
    "        self.base_models_[1].fit(X2, y)\n",
    "        meta_features = self._get_meta_features(X1, X2)\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        self.meta_model_.fit(meta_features, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X1, X2):\n",
    "        meta_features = self._get_meta_features(X1, X2)\n",
    "        return self.meta_model_.predict(meta_features)\n",
    "    \n",
    "    def predict_proba(self, X1, X2):\n",
    "        meta_features = self._get_meta_features(X1, X2)\n",
    "        return self.meta_model_.predict_proba(meta_features)\n",
    "    \n",
    "    def _get_meta_features(self, X1, X2):\n",
    "        meta_X1 = self.base_models_[0].predict_proba(X1)[:, 1]\n",
    "        meta_X2 = self.base_models_[1].predict_proba(X2)[:, 1]\n",
    "        return np.column_stack((meta_X1, meta_X2))\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Evaluate unimodal model performance\n",
    "# =============================================================================\n",
    "def evaluate_model_performance(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance on train and test sets\"\"\"\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    train_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_scores = cross_val_score(model, X_test, y_test, cv=kf, scoring='roc_auc')\n",
    "    y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(f\"\\n{model_name} model evaluation:\")\n",
    "    print(f\"Train CV AUC: {train_scores.mean():.2f} +/- {train_scores.std():.2f}\")\n",
    "    print(f\"Train AUC: {train_auc:.2f}\")\n",
    "    print(f\"Test CV AUC: {test_scores.mean():.2f} +/- {test_scores.std():.2f}\")\n",
    "    print(f\"Test AUC: {test_auc:.2f}\")\n",
    "    return model, train_scores, test_scores, train_auc, test_auc\n",
    "\n",
    "# Base models\n",
    "rotation_forest = RandomForestClassifier(\n",
    "    n_estimators=30,\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "base_rf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "boosting_model = AdaBoostClassifier(\n",
    "    estimator=base_rf,\n",
    "    n_estimators=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Evaluate clinical modality model\n",
    "clinical_model, clinical_train_scores, clinical_test_scores, clinical_train_auc, clinical_test_auc = \\\n",
    "    evaluate_model_performance(rotation_forest, X1_train_s, X1_test_s, y1_train, y1_test, \"Clinical Modality (Rotation Forest)\")\n",
    "\n",
    "# Evaluate imaging modality model\n",
    "imaging_model, imaging_train_scores, imaging_test_scores, imaging_train_auc, imaging_test_auc = \\\n",
    "    evaluate_model_performance(boosting_model, X2_train_s, X2_test_s, y2_train, y2_test, \"Imaging Modality (Boosting)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Build and evaluate late fusion model\n",
    "# =============================================================================\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "late_fusion_model = LateFusionClassifier(\n",
    "    base_models=[rotation_forest, boosting_model],\n",
    "    meta_model=LogisticRegression(random_state=42, penalty='l2', C=0.1)\n",
    ")\n",
    "\n",
    "# Evaluate fusion model on training set\n",
    "train_late_auc_scores = []\n",
    "for train_idx, val_idx in kf.split(X1_train_s):\n",
    "    X1_train_fold, X1_val_fold = X1_train_s[train_idx], X1_train_s[val_idx]\n",
    "    X2_train_fold, X2_val_fold = X2_train_s[train_idx], X2_train_s[val_idx]\n",
    "    y_train_fold, y_val_fold = y1_train[train_idx], y1_train[val_idx]\n",
    "    model = clone(late_fusion_model)\n",
    "    model.fit(X1_train_fold, X2_train_fold, y_train_fold)\n",
    "    y_prob = model.predict_proba(X1_val_fold, X2_val_fold)[:, 1]\n",
    "    auc_val = roc_auc_score(y_val_fold, y_prob)\n",
    "    train_late_auc_scores.append(auc_val)\n",
    "\n",
    "# Evaluate fusion model on test set\n",
    "test_late_auc_scores = []\n",
    "for train_idx, val_idx in kf.split(X1_test_s):\n",
    "    X1_val_train, X1_val_test = X1_test_s[train_idx], X1_test_s[val_idx]\n",
    "    X2_val_train, X2_val_test = X2_test_s[train_idx], X2_test_s[val_idx]\n",
    "    y_val_train, y_val_test = y1_test[train_idx], y1_test[val_idx]\n",
    "    model = clone(late_fusion_model)\n",
    "    model.fit(X1_val_train, X2_val_train, y_val_train)\n",
    "    y_prob = model.predict_proba(X1_val_test, X2_val_test)[:, 1]\n",
    "    auc_val = roc_auc_score(y_val_test, y_prob)\n",
    "    test_late_auc_scores.append(auc_val)\n",
    "\n",
    "print(\"\\nLate fusion model evaluation:\")\n",
    "print(\"Train CV AUC: {:.2f} +/- {:.2f}\".format(\n",
    "    np.mean(train_late_auc_scores), np.std(train_late_auc_scores)))\n",
    "print(\"Test CV AUC: {:.2f} +/- {:.2f}\".format(\n",
    "    np.mean(test_late_auc_scores), np.std(test_late_auc_scores)))\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Performance comparison visualization\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Train final fusion model\n",
    "late_fusion_model.fit(X1_test_s, X2_test_s, y1_test)\n",
    "\n",
    "print(\"\\nModel performance summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"{:<20} {:<25} {:<25}\".format(\"Model\", \"Training CV AUC\", \"Testing CV AUC\"))\n",
    "print(\"-\" * 80)\n",
    "print(\"{:<20} {:.2f} ± {:.2f} {:<10} {:.2f} ± {:.2f}\".format(\n",
    "    \"Clinical Model\",\n",
    "    np.mean(clinical_train_scores), np.std(clinical_train_scores),\n",
    "    \"\",\n",
    "    np.mean(clinical_test_scores), np.std(clinical_test_scores)))\n",
    "print(\"{:<20} {:.2f} ± {:.2f} {:<10} {:.2f} ± {:.2f}\".format(\n",
    "    \"Imaging Model\",\n",
    "    np.mean(imaging_train_scores), np.std(imaging_train_scores),\n",
    "    \"\",\n",
    "    np.mean(imaging_test_scores), np.std(imaging_test_scores)))\n",
    "print(\"{:<20} {:.2f} ± {:.2f} {:<10} {:.2f} ± {:.2f}\".format(\n",
    "    \"Fusion Model\",\n",
    "    np.mean(train_late_auc_scores), np.std(train_late_auc_scores),\n",
    "    \"\",\n",
    "    np.mean(test_late_auc_scores), np.std(test_late_auc_scores)))\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b09889e-1e76-420e-9601-075122f42b44",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ Clinical feature selection\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import rankdata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_univariate_logistic(p_values, feature_names, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize p-values from univariate logistic regression\n",
    "    \"\"\"\n",
    "    mpl.rcParams['font.family'] = 'Arial'\n",
    "    mpl.rcParams['font.size'] = 16\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    significance_threshold = 0.05\n",
    "    sorted_indices = np.argsort(p_values)\n",
    "    \n",
    "    # Blue for significant, gray for not significant features\n",
    "    colors = ['#3498db' if p <= significance_threshold else '#bdc3c7' \n",
    "             for p in p_values[sorted_indices]]\n",
    "    \n",
    "    bars = plt.bar(range(len(p_values)), -np.log10(p_values[sorted_indices]), color=colors)\n",
    "    \n",
    "    plt.axhline(y=-np.log10(significance_threshold), color='red', linestyle='--', \n",
    "                label=f'Significance threshold (p={significance_threshold})')\n",
    "    \n",
    "    plt.xticks(range(len(p_values)), feature_names[sorted_indices], rotation=45, ha='right', fontsize=16)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.ylabel('-log10(p-value)', fontsize=20)\n",
    "    plt.title(' ')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_elastic_net(model, feature_names, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize the feature coefficients from elastic net regression\n",
    "    \"\"\"\n",
    "    mpl.rcParams['font.family'] = 'Arial'\n",
    "    mpl.rcParams['font.size'] = 24\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    coefficients = model.coef_.flatten()\n",
    "    sorted_indices = np.argsort(np.abs(coefficients))\n",
    "    \n",
    "    colors = ['#e74c3c' if coef < 0 else '#3498db' \n",
    "             for coef in coefficients[sorted_indices]]\n",
    "    \n",
    "    plt.barh(range(len(coefficients)), coefficients[sorted_indices], color=colors)\n",
    "    plt.yticks(range(len(coefficients)), feature_names[sorted_indices])\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    # plt.title('Selected Features Coefficient')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualization example usage:\n",
    "# 1. Visualize univariate logistic regression results\n",
    "visualize_univariate_logistic(np.array(p_values), feature_names, 'univariate_selection.pdf')\n",
    "\n",
    "# 2. Visualize elastic net results\n",
    "visualize_elastic_net(elastic_net_model, feature_names[selected_features], 'elastic_net_selection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e462cfe-ba44-47a2-b9d1-a010d403777a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ Feature distribution heat map\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def create_abbreviated_feature_names(clinical_features, radiomic_features):\n",
    "    clinical_features = list(clinical_features)\n",
    "    radiomic_features = list(radiomic_features)\n",
    "    radiomic_short = [f\"RF {i+1}\" for i in range(len(radiomic_features))]\n",
    "    feature_name_abbr = clinical_features + radiomic_short\n",
    "    abbr_df = pd.DataFrame({\n",
    "        \"Radiomic Abbreviation\": radiomic_short,\n",
    "        \"Original Radiomic Feature Name\": radiomic_features\n",
    "    })\n",
    "    return feature_name_abbr, abbr_df, radiomic_short\n",
    "\n",
    "def plot_feature_heatmap(X1_train_s, X2_train_s, y1_train, selected_features_mod1, selected_features_mod2):\n",
    "    \"\"\"Plot optimized feature distribution heatmap with group color bar on top, \n",
    "    clinical features with original names, radiomic features as RF 1,2,..., larger Arial font, group labels Non-response/Response.\"\"\"\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "    plt.rcParams[\"axes.labelsize\"] = 22\n",
    "    plt.rcParams[\"xtick.labelsize\"] = 20\n",
    "    plt.rcParams[\"ytick.labelsize\"] = 24\n",
    "    plt.rcParams[\"legend.fontsize\"] = 22\n",
    "\n",
    "    all_features, radiomic_df, radiomic_short = create_abbreviated_feature_names(\n",
    "        selected_features_mod1, selected_features_mod2\n",
    "    )\n",
    "    radiomic_df.to_csv(\"radiomic_feature_abbreviation.csv\", index=False)\n",
    "\n",
    "    df1 = pd.DataFrame(X1_train_s, columns=selected_features_mod1)\n",
    "    df2 = pd.DataFrame(X2_train_s, columns=radiomic_short)\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    sort_idx = np.argsort(y1_train)\n",
    "    df_scaled_sorted = df_scaled.iloc[sort_idx]\n",
    "    y_sorted = np.array(y1_train)[sort_idx]\n",
    "\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    fig = plt.figure(figsize=(28, 12))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[0.8, 10], hspace=0.02)\n",
    "    \n",
    "    # Group color bar\n",
    "    ax_label = fig.add_subplot(gs[0])\n",
    "    n_non = sum(y_sorted == 0)\n",
    "    n_resp = sum(y_sorted == 1)\n",
    "    n_samples = len(y_sorted)\n",
    "    ax_label.axvspan(0, n_non, facecolor='#D6EAF8', alpha=0.5)\n",
    "    ax_label.axvspan(n_non, n_samples, facecolor='#D5F5E3', alpha=0.5)\n",
    "    ax_label.text(n_non/2, 0.5, f'Non-response (N={n_non})', \n",
    "                  ha='center', va='center', fontsize=28, fontweight='bold', family='Arial')\n",
    "    ax_label.text(n_non + n_resp/2, 0.5, f'Response (N={n_resp})', \n",
    "                  ha='center', va='center', fontsize=28, fontweight='bold', family='Arial')\n",
    "    ax_label.set_xlim(0, n_samples)\n",
    "    ax_label.set_ylim(0, 1)\n",
    "    ax_label.axis('off')\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[1])\n",
    "    sns.heatmap(\n",
    "        df_scaled_sorted.T,\n",
    "        ax=ax1,\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        vmin=-3,\n",
    "        vmax=3,\n",
    "        cbar_kws={'label': 'Standardized Value', 'pad': 0.01},\n",
    "        xticklabels=False,\n",
    "        yticklabels=True\n",
    "    )\n",
    "    ax1.axvline(n_non, color='black', linestyle='--', alpha=0.5)\n",
    "    ax1.set_yticklabels(df.columns, fontsize=25, family='Arial')\n",
    "    ax_label.set_position([\n",
    "        ax1.get_position().x0,\n",
    "        ax_label.get_position().y0,\n",
    "        ax1.get_position().width,\n",
    "        ax_label.get_position().height\n",
    "    ])\n",
    "    cbar = ax1.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=22)\n",
    "    cbar.set_label('Standardized Value', fontsize=26, family='Arial')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_heatmap_response_vs_nonresponse.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_pvalue_effectsize_bar(X1_train_s, X2_train_s, y1_train, selected_features_mod1, selected_features_mod2):\n",
    "    \"\"\"Plot bar chart of p-values and effect sizes, clinical features original names, radiomic features as RF 1,2,..., larger Arial font.\"\"\"\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "    plt.rcParams[\"axes.labelsize\"] = 22\n",
    "    plt.rcParams[\"xtick.labelsize\"] = 20\n",
    "    plt.rcParams[\"ytick.labelsize\"] = 24\n",
    "    plt.rcParams[\"legend.fontsize\"] = 22\n",
    "\n",
    "    all_features, radiomic_df, radiomic_short = create_abbreviated_feature_names(\n",
    "        selected_features_mod1, selected_features_mod2\n",
    "    )\n",
    "\n",
    "    df1 = pd.DataFrame(X1_train_s, columns=selected_features_mod1)\n",
    "    df2 = pd.DataFrame(X2_train_s, columns=radiomic_short)\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    p_values = {}\n",
    "    effect_sizes = {}\n",
    "    for col in df.columns:\n",
    "        pos_data = df[col][y1_train == 1]\n",
    "        neg_data = df[col][y1_train == 0]\n",
    "        t_stat, t_p = stats.ttest_ind(neg_data, pos_data)\n",
    "        u_stat, u_p = stats.mannwhitneyu(neg_data, pos_data, alternative='two-sided')\n",
    "        p_values[col] = {'t_test': t_p, 'mw_test': u_p}\n",
    "        d = (np.mean(pos_data) - np.mean(neg_data)) / np.sqrt((np.var(pos_data) + np.var(neg_data)) / 2)\n",
    "        effect_sizes[col] = abs(d)\n",
    "\n",
    "    fig, ax2 = plt.subplots(figsize=(28, 14))\n",
    "    p_val_df = pd.DataFrame({\n",
    "        'Feature': list(p_values.keys()),\n",
    "        't_test_p': [p_values[k]['t_test'] for k in p_values],\n",
    "        'mw_test_p': [p_values[k]['mw_test'] for k in p_values],\n",
    "        'Effect_Size': [effect_sizes[k] for k in p_values]\n",
    "    })\n",
    "    p_val_df = p_val_df.sort_values('Effect_Size', ascending=True)\n",
    "    x = np.arange(len(p_val_df))\n",
    "    width = 0.35\n",
    "    ax2.barh(x - width/2, -np.log10(p_val_df['t_test_p']), width, label='t-test', color='skyblue')\n",
    "    ax2.barh(x + width/2, -np.log10(p_val_df['mw_test_p']), width, label='Mann-Whitney U test', color='lightcoral')\n",
    "    for i, (idx, row) in enumerate(p_val_df.iterrows()):\n",
    "        ax2.text(0.1, i, f\"d={row['Effect_Size']:.2f}\", va='center', fontsize=28, family='Arial')\n",
    "    ax2.set_yticks(x)\n",
    "    ax2.set_yticklabels(p_val_df['Feature'], fontsize=32, family='Arial')\n",
    "    significance_levels = [0.05, 0.01, 0.001]\n",
    "    for level in significance_levels:\n",
    "        ax2.axvline(-np.log10(level), color='gray', linestyle='--', alpha=0.5)\n",
    "        ax2.text(-np.log10(level), len(p_val_df), f'p={level}', ha='center', va='bottom', fontsize=28, family='Arial')\n",
    "    ax2.set_xlabel('-log10(p-value)', fontsize=28, family='Arial')\n",
    "    ax2.legend(fontsize=28)\n",
    "    ax2.tick_params(axis='x', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_statistical_significance_bar.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_feature_heatmap(\n",
    "    X1_train_s, \n",
    "    X2_train_s, \n",
    "    y1_train, \n",
    "    feature_names1[multistep_selected_features],   # Clinical features\n",
    "    final_imaging_features                        # Radiomic features\n",
    ")\n",
    "plot_pvalue_effectsize_bar(\n",
    "    X1_train_s, \n",
    "    X2_train_s, \n",
    "    y1_train, \n",
    "    feature_names1[multistep_selected_features], \n",
    "    final_imaging_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb737d74-a670-4ffb-a83e-82baaf413956",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ P value difference map\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Global font settings\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "def plot_pvalue_bars(\n",
    "    X1_train_s, X2_train_s, y1_train,\n",
    "    selected_features_mod1, selected_features_mod2,\n",
    "    save_path=\"feature_pvalue.pdf\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot bar charts of p-values and effect sizes for features and save as PDF.\n",
    "    \"\"\"\n",
    "    df1 = pd.DataFrame(X1_train_s, columns=selected_features_mod1)\n",
    "    df2 = pd.DataFrame(X2_train_s, columns=selected_features_mod2)\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    p_values = {}\n",
    "    effect_sizes = {}\n",
    "    for col in df.columns:\n",
    "        pos_data = df[col][y1_train == 1]\n",
    "        neg_data = df[col][y1_train == 0]\n",
    "        t_stat, t_p = stats.ttest_ind(neg_data, pos_data)\n",
    "        u_stat, u_p = stats.mannwhitneyu(neg_data, pos_data, alternative='two-sided')\n",
    "        p_values[col] = {'t_test': t_p, 'mw_test': u_p}\n",
    "        d = (np.mean(pos_data) - np.mean(neg_data)) / np.sqrt((np.var(pos_data) + np.var(neg_data)) / 2)\n",
    "        effect_sizes[col] = abs(d)\n",
    "\n",
    "    p_val_df = pd.DataFrame({\n",
    "        'Feature': list(p_values.keys()),\n",
    "        't_test_p': [p_values[k]['t_test'] for k in p_values],\n",
    "        'mw_test_p': [p_values[k]['mw_test'] for k in p_values],\n",
    "        'Effect_Size': [effect_sizes[k] for k in p_values]\n",
    "    })\n",
    "    p_val_df = p_val_df.sort_values('Effect_Size', ascending=True)\n",
    "\n",
    "    x = np.arange(len(p_val_df))\n",
    "    width = 0.35\n",
    "    fig, ax2 = plt.subplots(figsize=(12, 12))\n",
    "    bars1 = ax2.barh(\n",
    "        x - width/2, -np.log10(p_val_df['t_test_p']),\n",
    "        width, label='t-test', color='skyblue'\n",
    "    )\n",
    "    bars2 = ax2.barh(\n",
    "        x + width/2, -np.log10(p_val_df['mw_test_p']),\n",
    "        width, label='Mann-Whitney U test', color='lightcoral'\n",
    "    )\n",
    "\n",
    "    for i, (idx, row) in enumerate(p_val_df.iterrows()):\n",
    "        ax2.text(0.1, i, f\"d={row['Effect_Size']:.2f}\", \n",
    "                 va='center', fontsize=16, fontname='Arial')\n",
    "\n",
    "    ax2.set_yticks(x)\n",
    "    ax2.set_yticklabels(p_val_df['Feature'], fontsize=16, fontname='Arial')\n",
    "    significance_levels = [0.05, 0.01, 0.001]\n",
    "    for level in significance_levels:\n",
    "        ax2.axvline(-np.log10(level), color='gray', linestyle='--', alpha=0.5)\n",
    "        ax2.text(-np.log10(level), len(p_val_df), f'p={level}', \n",
    "                 ha='center', va='bottom', fontsize=16, fontname='Arial')\n",
    "    plt.title('Statistical Significance and Effect Sizes', pad=20, fontsize=16, fontname='Arial')\n",
    "    plt.xlabel('-log10(p-value)', fontsize=16, fontname='Arial')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (replace with your actual variable names)\n",
    "plot_pvalue_bars(\n",
    "    X1_train_s, X2_train_s, y1_train,\n",
    "    feature_names1[multistep_selected_features],\n",
    "    final_imaging_features,\n",
    "    save_path='feature_pvalue.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325ab8db-41b1-4f21-a0e1-e3f99f503406",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ SHAP for fusion model\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# Assume variables are already defined:\n",
    "# X1_test_s, X2_test_s, late_fusion_model, feature_names1, multistep_selected_features, final_imaging_feature_names\n",
    "\n",
    "# Combine clinical and imaging test data into one array (fusion input)\n",
    "d1 = X1_test_s.shape[1]\n",
    "d2 = X2_test_s.shape[1]\n",
    "X_fusion = np.concatenate((X1_test_s, X2_test_s), axis=1)\n",
    "\n",
    "# Abbreviate imaging feature names (RF 1...), keep clinical feature names\n",
    "clinical_feature_names = list(feature_names1[multistep_selected_features])\n",
    "imaging_feature_names = list(final_imaging_feature_names)\n",
    "imaging_feature_names_abbr = [f\"RF {i+1}\" for i in range(len(imaging_feature_names))]\n",
    "fusion_feature_names = clinical_feature_names + imaging_feature_names_abbr\n",
    "\n",
    "# Save abbreviation table\n",
    "pd.DataFrame({\n",
    "    \"RF Abbreviation\": imaging_feature_names_abbr,\n",
    "    \"Original Imaging Feature Name\": imaging_feature_names\n",
    "}).to_csv(\"fusion_shap_rf_abbreviation.csv\", index=False)\n",
    "\n",
    "print(\"Fusion input shape:\", X_fusion.shape)\n",
    "print(\"Fusion feature names:\", fusion_feature_names)\n",
    "\n",
    "# Define a wrapper function for the fusion model.\n",
    "def fusion_model_wrapper(X):\n",
    "    X1 = X[:, :d1]\n",
    "    X2 = X[:, d1:]\n",
    "    return late_fusion_model.predict_proba(X1, X2)\n",
    "\n",
    "# Create a SHAP explainer for the fusion model.\n",
    "explainer_fusion = shap.Explainer(fusion_model_wrapper, X_fusion)\n",
    "\n",
    "# Compute SHAP values.\n",
    "shap_values_obj = explainer_fusion(X_fusion)\n",
    "shap_values_positive = shap_values_obj.values[:, :, 1]\n",
    "print(\"SHAP values shape for positive class:\", shap_values_positive.shape)\n",
    "\n",
    "# Construct DataFrames for the SHAP values and the fusion features.\n",
    "shap_df_fusion = pd.DataFrame(shap_values_positive, columns=fusion_feature_names)\n",
    "X_fusion_df = pd.DataFrame(X_fusion, columns=fusion_feature_names)\n",
    "print(\"SHAP DataFrame shape:\", shap_df_fusion.shape)\n",
    "\n",
    "# --- SHAP Scatter Plot Visualization ---\n",
    "jitter_scale = 0.15\n",
    "distance_threshold = 0.05\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom\", [\"#3465A4\", \"#E6E6E6\", \"#CC3333\"])\n",
    "\n",
    "# Compute mean absolute SHAP values and sort features\n",
    "mean_abs_shap_values = shap_df_fusion.abs().mean().sort_values(ascending=False)\n",
    "sorted_features = mean_abs_shap_values.index\n",
    "\n",
    "# Prepare plotting data\n",
    "plot_data = []\n",
    "for feature in sorted_features:\n",
    "    for shap_val, feature_val in zip(shap_df_fusion[feature], X_fusion_df[feature]):\n",
    "        normalized_value = (feature_val - X_fusion_df[feature].min()) / (\n",
    "            X_fusion_df[feature].max() - X_fusion_df[feature].min()\n",
    "        )\n",
    "        plot_data.append({\n",
    "            \"Feature\": feature, \n",
    "            \"SHAP Value\": shap_val, \n",
    "            \"Normalized Value\": normalized_value\n",
    "        })\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Create a KDTree for the SHAP values\n",
    "all_points = plot_df[\"SHAP Value\"].values.reshape(-1, 1)\n",
    "tree = KDTree(all_points)\n",
    "\n",
    "# --- Define feature groups and associated colors ---\n",
    "n_clinical = len(clinical_feature_names)\n",
    "feature_groups = {\n",
    "    \"Clinical\": fusion_feature_names[: n_clinical],\n",
    "    \"Imaging\": fusion_feature_names[n_clinical:]\n",
    "}\n",
    "group_colors = {\n",
    "    \"Clinical\": \"#ABDAEC\",\n",
    "    \"Imaging\": \"#6A9ACF\",\n",
    "}\n",
    "feature_colors = []\n",
    "for feature in sorted_features:\n",
    "    assigned_color = \"#cccccc\"\n",
    "    for group, features in feature_groups.items():\n",
    "        if feature in features:\n",
    "            assigned_color = group_colors.get(group, \"#000000\")\n",
    "            break\n",
    "    feature_colors.append(assigned_color)\n",
    "\n",
    "# --- Set up figure and grid layout ---\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "fig = plt.figure(figsize=(15, 14))\n",
    "gs = gridspec.GridSpec(2, 2, width_ratios=[0.85, 0.15], height_ratios=[0.05, 0.85])\n",
    "ax = plt.subplot(gs[1, 0])\n",
    "\n",
    "# Plot scatter points for each feature with jitter\n",
    "for i, feature in enumerate(sorted_features):\n",
    "    subset = plot_df[plot_df[\"Feature\"] == feature]\n",
    "    shap_values = subset[\"SHAP Value\"].values\n",
    "    jitter = np.zeros(len(shap_values))\n",
    "    for idx, shap_value in enumerate(shap_values):\n",
    "        neighbors = tree.query_ball_point([shap_value], r=distance_threshold)\n",
    "        if len(neighbors) > 1:\n",
    "            jitter[idx] = np.random.normal(loc=0, scale=jitter_scale)\n",
    "    ax.scatter(\n",
    "        subset[\"SHAP Value\"], \n",
    "        jitter + i,  # y position plus jitter\n",
    "        c=subset[\"Normalized Value\"],  \n",
    "        cmap=custom_cmap,  \n",
    "        s=28, \n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "# Add a vertical reference line at SHAP value 0.\n",
    "ax.axvline(x=0, color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.5)\n",
    "ax.set_yticks(range(len(sorted_features)))\n",
    "ax.set_yticklabels(sorted_features, fontsize=24, family=\"Arial\")\n",
    "ax.tick_params(axis='x', labelsize=24)\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_fontname('Arial')\n",
    "    label.set_fontsize(24)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(False)\n",
    "\n",
    "# --- Create a horizontal bar chart showing mean(|SHAP value|) per feature ---\n",
    "ax_bar = plt.subplot(gs[1, 1], sharey=ax)\n",
    "bars = ax_bar.barh(\n",
    "    range(len(sorted_features)),\n",
    "    mean_abs_shap_values.values,\n",
    "    color=feature_colors,\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax_bar.set_xlim(0, mean_abs_shap_values.max() * 2.0)\n",
    "ax_bar.set_xticks([])\n",
    "ax_bar.set_xlabel(\"|SHAP value|\", fontsize=22, family=\"Arial\", labelpad=15)\n",
    "for bar, value in zip(bars, mean_abs_shap_values.values):\n",
    "    ax_bar.text(\n",
    "        value + mean_abs_shap_values.max() * 0.02,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{value:.3f}\",\n",
    "        va=\"center\",\n",
    "        fontsize=24,\n",
    "        color=\"black\",\n",
    "        family=\"Arial\"\n",
    "    )\n",
    "ax_bar.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=False)\n",
    "ax_bar.grid(False)\n",
    "\n",
    "# --- Add a colorbar for the scatter plot ---\n",
    "cax = plt.subplot(gs[0, 0])\n",
    "sm = plt.cm.ScalarMappable(cmap=custom_cmap)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, cax=cax, orientation=\"horizontal\")\n",
    "cbar.outline.set_visible(False)\n",
    "cbar.ax.tick_params(labelsize=12, labelcolor=\"black\")\n",
    "cbar.ax.xaxis.set_ticks([])\n",
    "cbar.ax.text(-0.02, 0.5, \"Low\", ha=\"center\", va=\"center\", transform=cbar.ax.transAxes, fontsize=24, family=\"Arial\")\n",
    "cbar.ax.text(1.02, 0.5, \"High\", ha=\"center\", va=\"center\", transform=cbar.ax.transAxes, fontsize=24, family=\"Arial\")\n",
    "\n",
    "plt.subplots_adjust(top=0.8, wspace=0.05)\n",
    "plt.savefig(\"fusion_shap for response.pdf\", format=\"pdf\", bbox_inches=\"tight\", dpi=1200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Fusion SHAP visualization finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1429896-2c0c-47e3-92ca-998babfa1f37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ DCA curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "\n",
    "def calculate_net_benefit(y_true, y_pred_prob, threshold):\n",
    "    \"\"\"Calculate net benefit at a specific threshold.\"\"\"\n",
    "    y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    n = len(y_true)\n",
    "    \n",
    "    if TP + FP == 0:\n",
    "        return 0\n",
    "    \n",
    "    net_benefit = (TP/n) - (FP/n) * (threshold/(1-threshold))\n",
    "    return net_benefit\n",
    "\n",
    "def plot_dca_curves(X1_train, X2_train, y_train, X1_test, X2_test, y_test, \n",
    "                   clinical_model, imaging_model, late_fusion_model, dataset_type=\"Test\"):\n",
    "    \"\"\"Plot optimized DCA curves (no title).\"\"\"\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    \n",
    "    if dataset_type == \"Train\":\n",
    "        X1, X2, y = X1_train, X2_train, y_train\n",
    "    else:\n",
    "        X1, X2, y = X1_test, X2_test, y_test\n",
    "    \n",
    "    # Fit models and predict probabilities\n",
    "    clinical_model_fitted = clone(clinical_model).fit(X1, y)\n",
    "    imaging_model_fitted = clone(imaging_model).fit(X2, y)\n",
    "    fusion_model_fitted = clone(late_fusion_model)\n",
    "    fusion_model_fitted.fit(X1, X2, y)\n",
    "    \n",
    "    y_pred_clinical = clinical_model_fitted.predict_proba(X1)[:, 1]\n",
    "    y_pred_imaging = imaging_model_fitted.predict_proba(X2)[:, 1]\n",
    "    y_pred_fusion = fusion_model_fitted.predict_proba(X1, X2)[:, 1]\n",
    "    \n",
    "    # Calculate net benefits\n",
    "    nb_clinical = [calculate_net_benefit(y, y_pred_clinical, threshold) for threshold in thresholds]\n",
    "    nb_imaging = [calculate_net_benefit(y, y_pred_imaging, threshold) for threshold in thresholds]\n",
    "    nb_fusion = [calculate_net_benefit(y, y_pred_fusion, threshold) for threshold in thresholds]\n",
    "    nb_all = [calculate_net_benefit(y, np.ones_like(y), threshold) for threshold in thresholds]\n",
    "    nb_none = np.zeros_like(thresholds)\n",
    "    \n",
    "    # Optimized plotting\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    \n",
    "    # Elegant color scheme\n",
    "    plt.plot(thresholds, nb_clinical, '--', color='#4B88B5', linewidth=2, label='Clinical Model')\n",
    "    plt.plot(thresholds, nb_imaging, '--', color='#50A35D', linewidth=2, label='Imaging Model')\n",
    "    plt.plot(thresholds, nb_fusion, '-', color='#C44E52', linewidth=2, label='Fusion Model')\n",
    "    plt.plot(thresholds, nb_all, '--', color='#808080', linewidth=1.5, label='Treat All')\n",
    "    plt.plot(thresholds, nb_none, ':', color='#808080', linewidth=1.5, label='Treat None')\n",
    "    \n",
    "    plt.xlabel('Threshold Probability', fontsize=22)\n",
    "    plt.ylabel('Net Benefit', fontsize=22)\n",
    "    # No title as requested\n",
    "    \n",
    "    plt.legend(loc='lower left', frameon=False, fontsize=20)\n",
    "    plt.grid(False)\n",
    "    plt.axhline(y=0, color='k', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    plt.axvline(x=0, color='k', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(min(min(nb_clinical), min(nb_imaging), min(nb_fusion))-0.05,\n",
    "             max(max(nb_clinical), max(nb_imaging), max(nb_fusion))+0.05)\n",
    "    plt.xticks(fontsize=22)\n",
    "    plt.yticks(fontsize=22)\n",
    "    plt.savefig(f'dca_curves_{dataset_type.lower()}.pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Plot DCA curves for training set\n",
    "plot_dca_curves(X1_train_s, X2_train_s, y1_train,\n",
    "                X1_test_s, X2_test_s, y1_test,\n",
    "                clinical_model, imaging_model, late_fusion_model, \n",
    "                dataset_type=\"Train\")\n",
    "\n",
    "# Plot DCA curves for test set\n",
    "plot_dca_curves(X1_train_s, X2_train_s, y1_train,\n",
    "                X1_test_s, X2_test_s, y1_test,\n",
    "                clinical_model, imaging_model, late_fusion_model, \n",
    "                dataset_type=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11bada52-be79-46f1-84fc-e778eebd0531",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ Calibration curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_calibration_curves(y_train, y_test, probs_train, probs_test, model_names):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Calibration plot for training set\n",
    "    ax1.plot([0, 1], [0, 1], 'k:', label='Perfectly calibrated')\n",
    "    for name, probs in zip(model_names, probs_train):\n",
    "        prob_true, prob_pred = calibration_curve(y_train, probs, n_bins=5)\n",
    "        ax1.plot(prob_pred, prob_true, marker='o', label=name)\n",
    "    \n",
    "    ax1.set_xlabel('Mean predicted probability')\n",
    "    ax1.set_ylabel('Fraction of positives')\n",
    "    ax1.set_title('Calibration Plot (Training Set)')\n",
    "    ax1.legend(loc='lower right')\n",
    "    \n",
    "    # Set grid for training set\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.grid(True, which='minor', alpha=0.1)\n",
    "    ax1.minorticks_on()\n",
    "    \n",
    "    # Calibration plot for test set\n",
    "    ax2.plot([0, 1], [0, 1], 'k:', label='Perfectly calibrated')\n",
    "    for name, probs in zip(model_names, probs_test):\n",
    "        prob_true, prob_pred = calibration_curve(y_test, probs, n_bins=5)\n",
    "        ax2.plot(prob_pred, prob_true, marker='o', label=name)\n",
    "    \n",
    "    ax2.set_xlabel('Mean predicted probability')\n",
    "    ax2.set_ylabel('Fraction of positives')\n",
    "    ax2.set_title('Calibration Plot (Test Set)')\n",
    "    ax2.legend(loc='lower right')\n",
    "    \n",
    "    # Set grid for test set\n",
    "    ax2.grid(True, alpha=0.1)\n",
    "    ax2.grid(True, which='minor', alpha=0)\n",
    "    ax2.minorticks_on()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('calibration_curves.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Prepare training set predicted probabilities\n",
    "clinical_probs_train = clinical_model.predict_proba(X1_train_s)[:, 1]\n",
    "imaging_probs_train = imaging_model.predict_proba(X2_train_s)[:, 1]\n",
    "\n",
    "# Prepare fusion features\n",
    "X_fusion_train = np.hstack((X1_train_s, X2_train_s))\n",
    "X_fusion_test = np.hstack((X1_test_s, X2_test_s))\n",
    "\n",
    "# Train a fusion model using RandomForest for calibration\n",
    "fusion_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "fusion_classifier.fit(X_fusion_train, y1_train)\n",
    "\n",
    "# Get predicted probabilities for fusion model\n",
    "fusion_probs_train = fusion_classifier.predict_proba(X_fusion_train)[:, 1]\n",
    "fusion_probs_test = fusion_classifier.predict_proba(X_fusion_test)[:, 1]\n",
    "\n",
    "# Prepare test set predicted probabilities\n",
    "clinical_probs_test = clinical_model.predict_proba(X1_test_s)[:, 1]\n",
    "imaging_probs_test = imaging_model.predict_proba(X2_test_s)[:, 1]\n",
    "\n",
    "# Model names\n",
    "model_names = ['Clinical Model', 'Imaging Model', 'Fusion Model']\n",
    "\n",
    "# Probabilities for train and test\n",
    "probs_train = [clinical_probs_train, imaging_probs_train, fusion_probs_train]\n",
    "probs_test = [clinical_probs_test, imaging_probs_test, fusion_probs_test]\n",
    "\n",
    "# Plot calibration curves\n",
    "plot_calibration_curves(y1_train, y1_test, probs_train, probs_test, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3309ad2f-19a6-45f7-8f54-d4531bb50e38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ Model selection performance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 数据部分，'CR'改为'Fusion'\n",
    "data = {\n",
    "    'Model_Type': ['Radiomics']*5 + ['Clinical']*5 + ['Early Fusion']*5,\n",
    "    'Algorithm': ['Bagging', 'Boosting', 'Stacking', 'RF', 'GTBR']*3,\n",
    "    'Training': [0.76, 0.78, 0.76, 0.78, 0.72,\n",
    "                0.76, 0.76, 0.79, 0.74, 0.74,\n",
    "                0.81, 0.84, 0.75, 0.84, 0.79],\n",
    "    'Training_CI_Lower': [0.67, 0.68, 0.64, 0.66, 0.61,\n",
    "                         0.71, 0.70, 0.71, 0.68, 0.69,\n",
    "                         0.69, 0.72, 0.68, 0.74, 0.70],\n",
    "    'Training_CI_Upper': [0.85, 0.88, 0.88, 0.90, 0.83,\n",
    "                         0.81, 0.82, 0.87, 0.80, 0.79,\n",
    "                         0.92, 0.96, 0.82, 0.95, 0.88],\n",
    "    'Testing': [0.80, 0.86, 0.78, 0.85, 0.87,\n",
    "                0.73, 0.75, 0.73, 0.76, 0.55,\n",
    "                0.83, 0.86, 0.78, 0.87, 0.83],\n",
    "    'Testing_CI_Lower': [0.62, 0.74, 0.66, 0.72, 0.73,\n",
    "                        0.64, 0.56, 0.60, 0.64, 0.44,\n",
    "                        0.68, 0.74, 0.70, 0.75, 0.69],\n",
    "    'Testing_CI_Upper': [0.98, 0.98, 0.90, 0.98, 1.00,\n",
    "                        0.82, 0.94, 0.86, 0.88, 0.66,\n",
    "                        0.98, 0.98, 0.85, 0.98, 0.97]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 设置全局字体为Arial，字体大小同前\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rcParams[\"axes.labelsize\"] = 20\n",
    "plt.rcParams[\"xtick.labelsize\"] = 20\n",
    "plt.rcParams[\"ytick.labelsize\"] = 20\n",
    "plt.rcParams[\"legend.fontsize\"] = 24\n",
    "plt.rcParams[\"figure.titlesize\"] = 22\n",
    "\n",
    "plt.figure(figsize=(25, 8))\n",
    "ax = plt.gca()\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "colors = ['#8ecae6', '#219ebc']\n",
    "n_algorithms = 5\n",
    "width = 0.40\n",
    "group_spacing = 0.8\n",
    "\n",
    "model_types = ['Radiomics', 'Clinical', 'Early Fusion']\n",
    "\n",
    "for i, model_type in enumerate(model_types):\n",
    "    model_data = df[df['Model_Type'] == model_type]\n",
    "    x = np.arange(n_algorithms) + i * (n_algorithms + group_spacing)\n",
    "    # 训练集\n",
    "    train_bars = ax.bar(x - width/2, model_data['Training'], width, \n",
    "                       label='Training' if i == 0 else \"\", color=colors[0])\n",
    "    # 测试集\n",
    "    test_bars = ax.bar(x + width/2, model_data['Testing'], width,\n",
    "                      label='Test' if i == 0 else \"\", color=colors[1])\n",
    "    # 训练误差棒\n",
    "    ax.errorbar(x - width/2, model_data['Training'],\n",
    "           yerr=[model_data['Training'] - model_data['Training_CI_Lower'],\n",
    "                 model_data['Training_CI_Upper'] - model_data['Training']],\n",
    "           fmt='none', color='black', capsize=5, alpha=0.2,\n",
    "           elinewidth=0.8, capthick=0.8)\n",
    "    # 测试误差棒\n",
    "    ax.errorbar(x + width/2, model_data['Testing'],\n",
    "           yerr=[model_data['Testing'] - model_data['Testing_CI_Lower'],\n",
    "                 model_data['Testing_CI_Upper'] - model_data['Testing']],\n",
    "           fmt='none', color='black', capsize=5, alpha=0.2,\n",
    "           elinewidth=0.8, capthick=0.8)\n",
    "    # 添加数值标签\n",
    "    for bars in [train_bars, test_bars]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=20, fontfamily=\"Arial\")\n",
    "    # 上方模型类型标签\n",
    "    plt.text((i * (n_algorithms + group_spacing) + 2), 1.08, model_type,\n",
    "             ha='center', va='bottom', fontsize=28, fontweight='bold', fontfamily=\"Arial\")\n",
    "    # 垂直分隔虚线\n",
    "    if i < 2:\n",
    "        separation_x = x[-1] + width + group_spacing/2\n",
    "        plt.axvline(x=separation_x, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "# 设置x轴标签\n",
    "all_x = np.array([np.arange(n_algorithms) + i * (n_algorithms + group_spacing) for i in range(3)]).flatten()\n",
    "plt.xticks(all_x, ['Bagging', 'Boosting', 'Stacking', 'RF', 'GTBR'] * 3, rotation=0, fontfamily=\"Arial\", fontsize=20)\n",
    "\n",
    "# plt.xlabel('Algorithm', fontsize=18, labelpad=10, fontfamily=\"Arial\")\n",
    "plt.ylabel('AUC', fontsize=20, fontfamily=\"Arial\")\n",
    "# plt.title('AUC Comparison Across Different Models',\n",
    "#           fontsize=22, pad=20, fontfamily=\"Arial\")\n",
    "plt.legend(loc='upper right', frameon=False)\n",
    "\n",
    "plt.ylim(0, 1.12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"auc_multimodel.pdf\", format=\"pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a093427a-a91d-453e-81a2-aeb4bfc0957f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ Final AUC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Model': ['Clinical Model', 'Radiomics Model', 'LFICKI-TR'],\n",
    "    'Training': [0.76, 0.76, 0.82],\n",
    "    'Training_CI_Lower': [0.71, 0.66, 0.72],\n",
    "    'Training_CI_Upper': [0.81, 0.86, 0.92],\n",
    "    'Testing': [0.73, 0.88, 0.90],\n",
    "    'Testing_CI_Lower': [0.50, 0.78, 0.80],\n",
    "    'Testing_CI_Upper': [0.96, 0.98, 1.00],\n",
    "    'External': [0.70, 0.84, 0.85]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set global font to Arial\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rcParams[\"axes.labelsize\"] = 18\n",
    "plt.rcParams[\"xtick.labelsize\"] = 18\n",
    "plt.rcParams[\"ytick.labelsize\"] = 22\n",
    "plt.rcParams[\"legend.fontsize\"] = 22\n",
    "plt.rcParams[\"figure.titlesize\"] = 22\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"white\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Color-blind friendly, high contrast\n",
    "colors = ['#8ecae6', '#219ebc', '#126782']\n",
    "\n",
    "width = 0.25\n",
    "x = np.arange(len(data['Model']))\n",
    "\n",
    "# Bar plots\n",
    "train_bars = ax.bar(x - width, df['Training'], width, label='Training', color=colors[0])\n",
    "test_bars = ax.bar(x, df['Testing'], width, label='Testing', color=colors[1])\n",
    "external_bars = ax.bar(x + width, df['External'], width, label='External Validation', color=colors[2])\n",
    "\n",
    "# Error bars\n",
    "ax.errorbar(x - width, df['Training'],\n",
    "           yerr=[df['Training'] - df['Training_CI_Lower'],\n",
    "                 df['Training_CI_Upper'] - df['Training']],\n",
    "           fmt='none', color='black', capsize=5, alpha=0.3,\n",
    "           elinewidth=1.5, capthick=1.5)\n",
    "\n",
    "ax.errorbar(x, df['Testing'],\n",
    "           yerr=[df['Testing'] - df['Testing_CI_Lower'],\n",
    "                 df['Testing_CI_Upper'] - df['Testing']],\n",
    "           fmt='none', color='black', capsize=5, alpha=0.3,\n",
    "           elinewidth=1.5, capthick=1.5)\n",
    "\n",
    "# Value labels\n",
    "def add_value_labels(bars, fontsize=24):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=fontsize, fontfamily=\"Arial\")\n",
    "\n",
    "add_value_labels(train_bars)\n",
    "add_value_labels(test_bars)\n",
    "add_value_labels(external_bars)\n",
    "\n",
    "# X-axis labels\n",
    "plt.xticks(x, data['Model'], fontsize=24, fontfamily=\"Arial\")\n",
    "\n",
    "plt.ylabel('AUC', fontsize=24, fontfamily=\"Arial\")\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "\n",
    "ymin = 0.2\n",
    "max_heights_training = df['Training'] + (df['Training_CI_Upper'] - df['Training'])\n",
    "max_heights_testing = df['Testing'] + (df['Testing_CI_Upper'] - df['Testing'])\n",
    "ymax = max(max_heights_training.max(), max_heights_testing.max(), df['External'].max()) + 0.1\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"auc_comparison.pdf\", format=\"pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a54183b-37a4-4b0e-a76e-4e8d7ec5a99a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualization------------------------------------ Feature correlation matrix \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def create_abbreviated_feature_names(clinical_features, radiomic_features):\n",
    "    \"\"\"Generate RF 1,2,... abbreviations for radiomic features, and return mapping DataFrame.\"\"\"\n",
    "    clinical_features = list(clinical_features)\n",
    "    radiomic_features = list(radiomic_features)\n",
    "    radiomic_short = [f\"RF {i+1}\" for i in range(len(radiomic_features))]\n",
    "    feature_name_abbr = clinical_features + radiomic_short\n",
    "    abbr_df = pd.DataFrame({\n",
    "        \"Radiomic Abbreviation\": radiomic_short,\n",
    "        \"Original Radiomic Feature Name\": radiomic_features\n",
    "    })\n",
    "    return feature_name_abbr, abbr_df, radiomic_short\n",
    "\n",
    "def plot_feature_correlation_matrix(X1_train_s, X2_train_s, selected_features_mod1, selected_features_mod2):\n",
    "    \"\"\"\n",
    "    Plot feature correlation matrix (radiomic features auto-abbreviated as RF, Arial font, \n",
    "    bigger font size, only last row and first column have labels).\n",
    "    \"\"\"\n",
    "    # Set global font\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "    # Feature name abbreviation\n",
    "    all_features, radiomic_df, radiomic_short = create_abbreviated_feature_names(\n",
    "        list(selected_features_mod1), list(selected_features_mod2)\n",
    "    )\n",
    "    # Save mapping\n",
    "    radiomic_df.to_csv(\"radiomic_feature_abbreviation.csv\", index=False)\n",
    "\n",
    "    # Merge data and feature names\n",
    "    df = pd.DataFrame(np.hstack([X1_train_s, X2_train_s]),\n",
    "                     columns=all_features)\n",
    "    n = len(df.columns)\n",
    "    \n",
    "    # Compute correlation coefficient matrix and p-values\n",
    "    corr = df.corr()\n",
    "    p_values = pd.DataFrame(np.zeros((n, n)), columns=df.columns, index=df.columns)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                _, p = pearsonr(df.iloc[:, i], df.iloc[:, j])\n",
    "                p_values.iloc[i, j] = p\n",
    "\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(n, n, figsize=(2.3 * n, 2.3 * n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            ax = axes[i, j]\n",
    "            if i == j:\n",
    "                # Diagonal: plot histogram\n",
    "                sns.histplot(df.iloc[:, i], kde=True, ax=ax)\n",
    "                ax.set_title(df.columns[i], fontsize=18, pad=6, family=\"Arial\")\n",
    "            elif i > j:\n",
    "                # Lower triangle: scatter with fit line and confidence interval\n",
    "                sns.scatterplot(x=df.iloc[:, j], y=df.iloc[:, i], ax=ax, edgecolor=None)\n",
    "                X = sm.add_constant(df.iloc[:, j])\n",
    "                model = sm.OLS(df.iloc[:, i], X).fit()\n",
    "                x_values = np.linspace(df.iloc[:, j].min(), df.iloc[:, j].max(), 100)\n",
    "                X_pred = sm.add_constant(x_values)\n",
    "                y_pred = model.predict(X_pred)\n",
    "                conf_int_pred = model.get_prediction(X_pred).conf_int()\n",
    "                ax.plot(x_values, y_pred, color=\"red\")\n",
    "                ax.fill_between(x_values, conf_int_pred[:, 0], conf_int_pred[:, 1], \n",
    "                              color=\"blue\", alpha=0.2)\n",
    "            else:\n",
    "                # Upper triangle: heatmap with significance annotation\n",
    "                sns.heatmap(pd.DataFrame([[corr.iloc[i, j]]]), \n",
    "                          cmap=sns.diverging_palette(240, 10, as_cmap=True),\n",
    "                          cbar=False, annot=True, fmt=\".2f\", square=True, \n",
    "                          ax=ax, vmin=-1, vmax=1,\n",
    "                          annot_kws={\"size\": 22, \"family\": \"Arial\"})\n",
    "                # Significance annotation\n",
    "                p_val = p_values.iloc[i, j]\n",
    "                if p_val < 0.001:\n",
    "                    ax.text(0.5, 0.8, \"***\", color=\"black\", ha=\"center\", \n",
    "                           va=\"center\", transform=ax.transAxes, fontsize=16, family=\"Arial\")\n",
    "                elif p_val < 0.01:\n",
    "                    ax.text(0.5, 0.8, \"**\", color=\"black\", ha=\"center\", \n",
    "                           va=\"center\", transform=ax.transAxes, fontsize=16, family=\"Arial\")\n",
    "                elif p_val < 0.05:\n",
    "                    ax.text(0.5, 0.8, \"*\", color=\"black\", ha=\"center\", \n",
    "                           va=\"center\", transform=ax.transAxes, fontsize=16, family=\"Arial\")\n",
    "\n",
    "            # Axis labels: only keep for last row and first column\n",
    "            if i < n - 1:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xticklabels([])\n",
    "            else:\n",
    "                ax.set_xticks([0.5])\n",
    "                ax.set_xticklabels([df.columns[j]], fontsize=16, family=\"Arial\", rotation=60, ha=\"right\")\n",
    "            if j > 0:\n",
    "                ax.set_yticks([])\n",
    "                ax.set_yticklabels([])\n",
    "            else:\n",
    "                ax.set_yticks([0.5])\n",
    "                ax.set_yticklabels([df.columns[i]], fontsize=16, family=\"Arial\", rotation=0, va=\"center\")\n",
    "\n",
    "            # Diagonal: adjust title position\n",
    "            if i == j:\n",
    "                ax.set_title(df.columns[i], fontsize=18, pad=6, family=\"Arial\")\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    # Add colorbar\n",
    "    fig.subplots_adjust(right=0.86)\n",
    "    cbar_ax = fig.add_axes([0.88, 0.15, 0.03, 0.7])\n",
    "    norm = plt.Normalize(vmin=-1, vmax=1)\n",
    "    sm_map = plt.cm.ScalarMappable(cmap=sns.diverging_palette(240, 10, as_cmap=True), \n",
    "                                  norm=norm)\n",
    "    sm_map.set_array([])\n",
    "    cbar = fig.colorbar(sm_map, cax=cbar_ax)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    cbar.set_label(\"Pearson correlation\", fontsize=20, family=\"Arial\")\n",
    "\n",
    "    plt.savefig(\"Feature_Correlation_Matrix.pdf\", format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nPlotting feature correlation matrix...\")\n",
    "plot_feature_correlation_matrix(\n",
    "    X1_train_s,\n",
    "    X2_train_s,\n",
    "    list(feature_names1[multistep_selected_features]),\n",
    "    list(final_imaging_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082f180-7f06-4701-8c9d-aa172fed2de5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# External validation\n",
    "# =============================================================================\n",
    "# 7. External Validation Set Evaluation\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "try:\n",
    "    # Load external validation clinical data\n",
    "    clinical_val_data_path = input(\"Please enter the external clinical validation file path: \").strip()\n",
    "    clinical_val_data = pd.read_excel(clinical_val_data_path)\n",
    "    X1_val = clinical_val_data.iloc[:, 1:].values\n",
    "    y1_val = clinical_val_data.iloc[:, 0].values\n",
    "\n",
    "    # Load external validation imaging data\n",
    "    imaging_val_data_path = input(\"Please enter the external imaging validation file path: \").strip()\n",
    "    imaging_val_data = pd.read_excel(imaging_val_data_path)\n",
    "    X2_val = imaging_val_data.iloc[:, 1:].values\n",
    "    y2_val = imaging_val_data.iloc[:, 0].values\n",
    "\n",
    "    # =============================================================================\n",
    "    # 7.1 Clinical data preprocessing and feature selection\n",
    "    # =============================================================================\n",
    "    # Standardization\n",
    "    X1_val_s = scaler1.transform(X1_val)\n",
    "    \n",
    "    # Apply previous feature selection\n",
    "    if len(multistep_selected_features) > 0:\n",
    "        X1_val_s = X1_val_s[:, multistep_selected_features]\n",
    "        print(\"\\nClinical features used for external validation:\")\n",
    "        print(feature_names1[multistep_selected_features])\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 7.2 Imaging data preprocessing and feature selection\n",
    "    # =============================================================================\n",
    "    # Standardization\n",
    "    X2_val_s = scaler2.transform(X2_val)\n",
    "    \n",
    "    # Apply previous feature selection\n",
    "    X2_val_s = var_thresh2.transform(X2_val_s)\n",
    "    X2_val_s = select_model2.transform(X2_val_s)\n",
    "\n",
    "    # =============================================================================\n",
    "    # 7.3 Evaluate unimodal models on external validation set\n",
    "    # =============================================================================\n",
    "    # Clinical model evaluation\n",
    "    clinical_val_pred = clinical_model.predict_proba(X1_val_s)[:, 1]\n",
    "    clinical_val_auc = roc_auc_score(y1_val, clinical_val_pred)\n",
    "    fpr_clinical_val, tpr_clinical_val, _ = roc_curve(y1_val, clinical_val_pred)\n",
    "    \n",
    "    # Imaging model evaluation\n",
    "    imaging_val_pred = imaging_model.predict_proba(X2_val_s)[:, 1]\n",
    "    imaging_val_auc = roc_auc_score(y2_val, imaging_val_pred)\n",
    "    fpr_imaging_val, tpr_imaging_val, _ = roc_curve(y2_val, imaging_val_pred)\n",
    "    \n",
    "    # Fusion model evaluation\n",
    "    fusion_val_pred = late_fusion_model.predict_proba(X1_val_s, X2_val_s)[:, 1]\n",
    "    fusion_val_auc = roc_auc_score(y1_val, fusion_val_pred)\n",
    "    fpr_fusion_val, tpr_fusion_val, _ = roc_curve(y1_val, fusion_val_pred)\n",
    "\n",
    "    # =============================================================================\n",
    "    # 7.4 Output external validation results\n",
    "    # =============================================================================\n",
    "    print(\"\\nExternal validation performance results:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"{:<20} {:<25}\".format(\"Model\", \"External Validation AUC\"))\n",
    "    print(\"-\" * 80)\n",
    "    print(\"{:<20} {:.4f}\".format(\"Clinical Model\", clinical_val_auc))\n",
    "    print(\"{:<20} {:.4f}\".format(\"Imaging Model\", imaging_val_auc))\n",
    "    print(\"{:<20} {:.4f}\".format(\"Fusion Model\", fusion_val_auc))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # =============================================================================\n",
    "    # 7.5 Plot ROC curves for external validation set\n",
    "    # =============================================================================\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    plt.plot(fpr_clinical_val, tpr_clinical_val, \n",
    "             label=f'Clinical Model (AUC = {clinical_val_auc:.4f})', \n",
    "             linestyle='--')\n",
    "    plt.plot(fpr_imaging_val, tpr_imaging_val, \n",
    "             label=f'Imaging Model (AUC = {imaging_val_auc:.4f})', \n",
    "             linestyle=':')\n",
    "    plt.plot(fpr_fusion_val, tpr_fusion_val, \n",
    "             label=f'Fusion Model (AUC = {fusion_val_auc:.4f})', \n",
    "             linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves on External Validation Set')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('external_validation_roc.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    # =============================================================================\n",
    "    # 7.6 Save validation results\n",
    "    # =============================================================================\n",
    "    validation_results = {\n",
    "        'Date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'User': 'DONGHAILU-1',\n",
    "        'Clinical_AUC': clinical_val_auc,\n",
    "        'Imaging_AUC': imaging_val_auc,\n",
    "        'Fusion_AUC': fusion_val_auc\n",
    "    }\n",
    "    \n",
    "    results_df = pd.DataFrame([validation_results])\n",
    "    results_df.to_csv('external_validation_results.csv', index=False)\n",
    "    \n",
    "    with open('external_validation_report.txt', 'w') as f:\n",
    "        f.write(f\"External Validation Results\\n\")\n",
    "        f.write(f\"Date: {validation_results['Date']}\\n\")\n",
    "        f.write(f\"User: {validation_results['User']}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(f\"Clinical Model AUC: {clinical_val_auc:.4f}\\n\")\n",
    "        f.write(f\"Imaging Model AUC: {imaging_val_auc:.4f}\\n\")\n",
    "        f.write(f\"Fusion Model AUC: {fusion_val_auc:.4f}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(\"\\nSelected Clinical Features:\\n\")\n",
    "        for feature in feature_names1[multistep_selected_features]:\n",
    "            f.write(f\"- {feature}\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the external validation data files. Please make sure the file paths are correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during external validation: {str(e)}\")\n",
    "\n",
    "print(\"\\nExternal validation evaluation completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39env",
   "language": "python",
   "name": "py39env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
